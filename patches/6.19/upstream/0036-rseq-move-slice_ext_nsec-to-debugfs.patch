From fb455bef1021ce7bdee2cce0f67c5844fe5a597e Mon Sep 17 00:00:00 2001
From: Peter Zijlstra <peterz@infradead.org>
Date: Wed, 21 Jan 2026 14:21:51 +0100
Subject: [PATCH 11/12] rseq: Move slice_ext_nsec to debugfs

Move changing the slice ext duration to debugfs, a sliglty less permanent
interface.

Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://patch.msgid.link/20260121143207.923520192@infradead.org
---
 Documentation/admin-guide/sysctl/kernel.rst | 11 ----
 Documentation/userspace-api/rseq.rst        |  4 +-
 kernel/rseq.c                               | 69 ++++++++++++++-------
 3 files changed, 49 insertions(+), 35 deletions(-)

diff --git a/Documentation/admin-guide/sysctl/kernel.rst b/Documentation/admin-guide/sysctl/kernel.rst
index b09d18e0f75b..239da22c4e28 100644
--- a/Documentation/admin-guide/sysctl/kernel.rst
+++ b/Documentation/admin-guide/sysctl/kernel.rst
@@ -1246,21 +1246,10 @@ reboot-cmd (SPARC only)
 
 ??? This seems to be a way to give an argument to the Sparc
 ROM/Flash boot loader. Maybe to tell it what to do after
 rebooting. ???
 
-rseq_slice_extension_nsec
-=========================
-
-A task can request to delay its scheduling if it is in a critical section
-via the prctl(PR_RSEQ_SLICE_EXTENSION_SET) mechanism. This sets the maximum
-allowed extension in nanoseconds before scheduling of the task is enforced.
-Default value is 10000ns (10us). The possible range is 10000ns (10us) to
-50000ns (50us).
-
-This value has a direct correlation to the worst case scheduling latency;
-increment at your own risk.
 
 sched_energy_aware
 ==================
 
 Enables/disables Energy Aware Scheduling (EAS). EAS starts
diff --git a/Documentation/userspace-api/rseq.rst b/Documentation/userspace-api/rseq.rst
index e1fdb0d5ce69..29af6c300396 100644
--- a/Documentation/userspace-api/rseq.rst
+++ b/Documentation/userspace-api/rseq.rst
@@ -77,11 +77,13 @@ space and only for informational purposes.
 If the mechanism was enabled via prctl(), the thread can request a time
 slice extension by setting rseq::slice_ctrl::request to 1. If the thread is
 interrupted and the interrupt results in a reschedule request in the
 kernel, then the kernel can grant a time slice extension and return to
 userspace instead of scheduling out. The length of the extension is
-determined by the ``rseq_slice_extension_nsec`` sysctl.
+determined by debugfs:rseq/slice_ext_nsec. The default value is 10 usec; which
+is the minimum value. It can be incremented to 50 usecs, however doing so
+can/will affect the minimum scheduling latency.
 
 The kernel indicates the grant by clearing rseq::slice_ctrl::request and
 setting rseq::slice_ctrl::granted to 1. If there is a reschedule of the
 thread after granting the extension, the kernel clears the granted bit to
 indicate that to userspace.
diff --git a/kernel/rseq.c b/kernel/rseq.c
index 1c5490a172a8..e423a9bc0a2c 100644
--- a/kernel/rseq.c
+++ b/kernel/rseq.c
@@ -121,11 +121,10 @@ void __rseq_trace_ip_fixup(unsigned long ip, unsigned long start_ip,
 {
 	trace_rseq_ip_fixup(ip, start_ip, offset, abort_ip);
 }
 #endif /* CONFIG_TRACEPOINTS */
 
-#ifdef CONFIG_DEBUG_FS
 #ifdef CONFIG_RSEQ_STATS
 DEFINE_PER_CPU(struct rseq_stats, rseq_stats);
 
 static int rseq_stats_show(struct seq_file *m, void *p)
 {
@@ -220,20 +219,23 @@ static const struct file_operations debug_ops = {
 	.write		= rseq_debug_write,
 	.llseek		= seq_lseek,
 	.release	= single_release,
 };
 
+static void rseq_slice_ext_init(struct dentry *root_dir);
+
 static int __init rseq_debugfs_init(void)
 {
 	struct dentry *root_dir = debugfs_create_dir("rseq", NULL);
 
 	debugfs_create_file("debug", 0644, root_dir, NULL, &debug_ops);
 	rseq_stats_init(root_dir);
+	if (IS_ENABLED(CONFIG_RSEQ_SLICE_EXTENSION))
+		rseq_slice_ext_init(root_dir);
 	return 0;
 }
 __initcall(rseq_debugfs_init);
-#endif /* CONFIG_DEBUG_FS */
 
 static bool rseq_set_ids(struct task_struct *t, struct rseq_ids *ids, u32 node_id)
 {
 	return rseq_set_ids_get_csaddr(t, ids, node_id, NULL);
 }
@@ -513,11 +515,13 @@ SYSCALL_DEFINE4(rseq, struct rseq __user *, rseq, u32, rseq_len, int, flags, u32
 struct slice_timer {
 	struct hrtimer	timer;
 	void		*cookie;
 };
 
-unsigned int rseq_slice_ext_nsecs __read_mostly = 10 * NSEC_PER_USEC;
+static const unsigned int rseq_slice_ext_nsecs_min = 10 * NSEC_PER_USEC;
+static const unsigned int rseq_slice_ext_nsecs_max = 50 * NSEC_PER_USEC;
+unsigned int rseq_slice_ext_nsecs __read_mostly = rseq_slice_ext_nsecs_min;
 static DEFINE_PER_CPU(struct slice_timer, slice_timer);
 DEFINE_STATIC_KEY_TRUE(rseq_slice_extension_key);
 
 /*
  * When the timer expires and the task is still in user space, the return
@@ -759,34 +763,52 @@ SYSCALL_DEFINE0(rseq_slice_yield)
 
 	current->rseq.slice.yielded = 0;
 	return yielded;
 }
 
-#ifdef CONFIG_SYSCTL
-static const unsigned int rseq_slice_ext_nsecs_min = 10 * NSEC_PER_USEC;
-static const unsigned int rseq_slice_ext_nsecs_max = 50 * NSEC_PER_USEC;
+static int rseq_slice_ext_show(struct seq_file *m, void *p)
+{
+	seq_printf(m, "%d\n", rseq_slice_ext_nsecs);
+	return 0;
+}
+
+static ssize_t rseq_slice_ext_write(struct file *file, const char __user *ubuf,
+				    size_t count, loff_t *ppos)
+{
+	unsigned int nsecs;
+
+	if (kstrtouint_from_user(ubuf, count, 10, &nsecs))
+		return -EINVAL;
+
+	if (nsecs < rseq_slice_ext_nsecs_min)
+		return -ERANGE;
 
-static const struct ctl_table rseq_slice_ext_sysctl[] = {
-	{
-		.procname	= "rseq_slice_extension_nsec",
-		.data		= &rseq_slice_ext_nsecs,
-		.maxlen		= sizeof(unsigned int),
-		.mode		= 0644,
-		.proc_handler	= proc_douintvec_minmax,
-		.extra1		= (unsigned int *)&rseq_slice_ext_nsecs_min,
-		.extra2		= (unsigned int *)&rseq_slice_ext_nsecs_max,
-	},
+	if (nsecs > rseq_slice_ext_nsecs_max)
+		return -ERANGE;
+
+	rseq_slice_ext_nsecs = nsecs;
+
+	return count;
+}
+
+static int rseq_slice_ext_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, rseq_slice_ext_show, inode->i_private);
+}
+
+static const struct file_operations slice_ext_ops = {
+	.open		= rseq_slice_ext_open,
+	.read		= seq_read,
+	.write		= rseq_slice_ext_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
 };
 
-static void rseq_slice_sysctl_init(void)
+static void rseq_slice_ext_init(struct dentry *root_dir)
 {
-	if (rseq_slice_extension_enabled())
-		register_sysctl_init("kernel", rseq_slice_ext_sysctl);
+	debugfs_create_file("slice_ext_nsec", 0644, root_dir, NULL, &slice_ext_ops);
 }
-#else /* CONFIG_SYSCTL */
-static inline void rseq_slice_sysctl_init(void) { }
-#endif  /* !CONFIG_SYSCTL */
 
 static int __init rseq_slice_cmdline(char *str)
 {
 	bool on;
 
@@ -805,10 +827,11 @@ static int __init rseq_slice_init(void)
 
 	for_each_possible_cpu(cpu) {
 		hrtimer_setup(per_cpu_ptr(&slice_timer.timer, cpu), rseq_slice_expired,
 			      CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED_HARD);
 	}
-	rseq_slice_sysctl_init();
 	return 0;
 }
 device_initcall(rseq_slice_init);
+#else
+static void rseq_slice_ext_init(struct dentry *root_dir) { }
 #endif /* CONFIG_RSEQ_SLICE_EXTENSION */
-- 
2.52.0

